{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOaaZ-M2xLuV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"NO GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets scikit-learn pandas torch\n"
      ],
      "metadata": {
        "id": "48p14gHuxVr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    get_scheduler\n",
        ")\n",
        "from torch.optim import AdamW # Corrected import path for AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n"
      ],
      "metadata": {
        "id": "kElH_j6lxVun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "_tm_5qjgxVxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "\n",
        "print(\"Dataset size:\", len(df))\n",
        "print(df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "id": "gCCbsbHoxVzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(30000, random_state=42)\n"
      ],
      "metadata": {
        "id": "F0aSTTXVxV2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"text\"].tolist()\n",
        "y = df[\"label\"].tolist()\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    stratify=y_temp,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(X_train))\n",
        "print(\"Validation:\", len(X_val))\n",
        "print(\"Test:\", len(X_test))\n"
      ],
      "metadata": {
        "id": "Vy37iXANxV4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LEN = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
      ],
      "metadata": {
        "id": "iofv3wyIxV78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_enc = tokenize(X_train)\n",
        "val_enc   = tokenize(X_val)\n",
        "test_enc  = tokenize(X_test)\n"
      ],
      "metadata": {
        "id": "w7YSClMFxV-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(\n",
        "    train_enc[\"input_ids\"],\n",
        "    train_enc[\"attention_mask\"],\n",
        "    torch.tensor(y_train)\n",
        ")\n",
        "\n",
        "val_dataset = TensorDataset(\n",
        "    val_enc[\"input_ids\"],\n",
        "    val_enc[\"attention_mask\"],\n",
        "    torch.tensor(y_val)\n",
        ")\n",
        "\n",
        "test_dataset = TensorDataset(\n",
        "    test_enc[\"input_ids\"],\n",
        "    test_enc[\"attention_mask\"],\n",
        "    torch.tensor(y_test)\n",
        ")\n"
      ],
      "metadata": {
        "id": "ab0B1BsnxWA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "dSqwByauxWDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "CkRbFzBIxWGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "total_steps = EPOCHS * len(train_loader)\n",
        "\n",
        "scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "3naeRp1lxWIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n"
      ],
      "metadata": {
        "id": "CZ1I1s7jxWMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    preds, labels_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            preds.extend(torch.argmax(outputs.logits, dim=1).cpu().tolist())\n",
        "            labels_all.extend(labels.cpu().tolist())\n",
        "\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    print(f\"Validation Accuracy: {acc:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "e-5nW_ol094T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds, labels_all = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds.extend(torch.argmax(outputs.logits, dim=1).cpu().tolist())\n",
        "        labels_all.extend(labels.cpu().tolist())\n",
        "\n",
        "print(classification_report(labels_all, preds, target_names=[\"REAL\", \"FAKE\"]))\n"
      ],
      "metadata": {
        "id": "ZtTO-9ek097E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"fake_news_model\")\n",
        "tokenizer.save_pretrained(\"fake_news_model\")\n"
      ],
      "metadata": {
        "id": "1rcokFQN09-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_news(text):\n",
        "    model.eval()\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=MAX_LEN\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**enc)\n",
        "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    return \"FAKE NEWS ðŸš¨\" if pred == 1 else \"REAL NEWS âœ…\"\n",
        "\n",
        "# Test\n",
        "predict_news(\"Breaking news: Aliens have landed in New York City\")\n"
      ],
      "metadata": {
        "id": "lzbwbNnc0-B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "mpSWG6zA0-Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bvQCQDz0-K1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}